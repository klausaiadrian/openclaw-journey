#!/usr/bin/env python3
"""
Blocket Browser Automation Skrapare
AnvÃ¤nder Playwright fÃ¶r att styra en riktig webblÃ¤sare
Ser ut som en vanlig anvÃ¤ndare fÃ¶r att undvika blockering
"""

import json
import re
import time
from datetime import datetime
from playwright.sync_api import sync_playwright

class BlocketBrowserScraper:
    def __init__(self, headless=False):
        """
        headless=False: Visar webblÃ¤saren (bra fÃ¶r debugging)
        headless=True: KÃ¶r i bakgrunden (snabbare)
        """
        self.headless = headless
        self.results = []
        
    def search_blocket(self, search_term, category="5000"):
        """
        SÃ¶k pÃ¥ Blocket med riktig webblÃ¤sare
        category 5000 = Datorer
        """
        with sync_playwright() as p:
            # Starta webblÃ¤sare
            print(f"ğŸš€ Startar webblÃ¤sare...")
            browser = p.chromium.launch(headless=self.headless)
            context = browser.new_context(
                user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            page = context.new_page()
            
            try:
                # Bygg URL
                url = f"https://www.blocket.se/q/{search_term}/f?cg={category}&q={search_term}"
                print(f"ğŸ” GÃ¥r till: {url}")
                
                # GÃ¥ till sidan
                page.goto(url, wait_until='networkidle', timeout=30000)
                
                # VÃ¤nta pÃ¥ att annonser laddas (Blocket anvÃ¤nder ofta JS)
                print(f"â³ VÃ¤ntar pÃ¥ att sidan laddas...")
                time.sleep(3)  # Ge JS tid att kÃ¶ra
                
                # Scrolla ner fÃ¶r att ladda mer (om infinite scroll)
                print(f"ğŸ“œ Scrollar ner...")
                for i in range(3):
                    page.keyboard.press('End')
                    time.sleep(1)
                
                # Extrahera annonser
                print(f"ğŸ“‹ HÃ¤mtar annonser...")
                listings = self._extract_listings(page, search_term)
                
                print(f"âœ… Hittade {len(listings)} annonser fÃ¶r '{search_term}'")
                
                browser.close()
                return listings
                
            except Exception as e:
                print(f"âŒ Fel: {e}")
                browser.close()
                return []
    
    def _extract_listings(self, page, search_term):
        """Extrahera annonsdata frÃ¥n sidan"""
        listings = []
        
        # FÃ¶rsÃ¶k hitta annons-element med olika selektorer
        # Blocket Ã¤ndrar ofta sin HTML-struktur
        
        selectors = [
            'article a[href*="/annons/"]',  # Vanligast
            '[data-testid="ad-list-item"] a',
            '.ad-card a',
            'a[href*="/annons/"]'
        ]
        
        for selector in selectors:
            try:
                elements = page.query_selector_all(selector)
                if elements:
                    print(f"   AnvÃ¤nder selektor: {selector} ({len(elements)} element)")
                    break
            except:
                continue
        else:
            print("   âš ï¸  Kunde inte hitta annonser med kÃ¤nda selektorer")
            # Spara HTML fÃ¶r debugging
            html = page.content()
            with open('/tmp/blocket_debug.html', 'w') as f:
                f.write(html)
            print("   ğŸ’¾ Sparade HTML till /tmp/blocket_debug.html")
            return []
        
        seen_urls = set()
        for element in elements[:15]:  # Max 15 per sÃ¶kning
            try:
                # Hitta lÃ¤nk
                href = element.get_attribute('href')
                if not href or href in seen_urls:
                    continue
                seen_urls.add(href)
                
                # GÃ¶r full URL
                if href.startswith('/'):
                    href = f"https://www.blocket.se{href}"
                
                # Hitta titel (text i lÃ¤nken eller nÃ¤rliggande element)
                title = element.inner_text().strip() or "OkÃ¤nd titel"
                
                # FÃ¶rsÃ¶k hitta pris (i parent eller sibling)
                price = "N/A"
                parent = element.evaluate('el => el.closest("article, div, li")')
                if parent:
                    price_elem = page.query_selector('text=\\d+\\s*kr')
                    if price_elem:
                        price = price_elem.inner_text().strip()
                
                # Extrahera annons-ID
                ad_id_match = re.search(r'/annons/(\\d+)', href)
                ad_id = ad_id_match.group(1) if ad_id_match else "unknown"
                
                listings.append({
                    'title': title,
                    'price': price,
                    'url': href,
                    'ad_id': ad_id,
                    'search_term': search_term
                })
                
            except Exception as e:
                print(f"   âš ï¸  Fel vid parsning: {e}")
                continue
        
        return listings
    
    def scrape_all(self):
        """Huvudfunktion - sÃ¶k alla relevanta termer"""
        print("=" * 60)
        print("ğŸ” BLOCKET BROWSER AUTOMATION SKRAPARE")
        print("=" * 60)
        print("AnvÃ¤nder riktig webblÃ¤sare fÃ¶r att se ut som vanlig anvÃ¤ndare")
        print("-" * 60 + "\\n")
        
        all_listings = []
        
        search_terms = [
            "mac mini",
            "intel nuc", 
            "mini pc",
            "beelink"
        ]
        
        for term in search_terms:
            print(f"\\nğŸ“± SÃ¶ker: '{term}'...")
            listings = self.search_blocket(term)
            
            if listings:
                all_listings.extend(listings)
                print(f"   âœ… {len(listings)} annonser")
            else:
                print(f"   âš ï¸  Inga resultat")
            
            # VÃ¤nta mellan sÃ¶kningar (var respektfull)
            time.sleep(2)
        
        # Ta bort duplikat
        unique = {item['url']: item for item in all_listings}.values()
        
        print(f"\\n{'=' * 60}")
        print(f"ğŸ“Š Totalt: {len(unique)} unika annonser")
        print(f"{'=' * 60}\\n")
        
        return list(unique)

# Import frÃ¥n tidigare fÃ¶r scoring
import sys
sys.path.insert(0, '/Users/duljan/.openclaw/workspace/projects/openclaw-journey')
from blocket_scraper import BlocketScraper

class BlocketBrowserScraperWithScoring(BlocketBrowserScraper):
    """Kombinerar browser scraping med scoring algoritm"""
    
    def analyze_results(self, results):
        """Analysera resultat med scoring"""
        base_scraper = BlocketScraper()
        analyzed = []
        
        for item in results:
            analysis = base_scraper.calculate_openclaw_score(item)
            item['analysis'] = analysis
            analyzed.append(item)
        
        # Sortera efter score
        analyzed.sort(key=lambda x: x['analysis']['score'], reverse=True)
        return analyzed
    
    def save_and_report(self, results, filename='blocket_browser_results.json'):
        """Spara och skriva rapport"""
        output = {
            'timestamp': datetime.now().isoformat(),
            'method': 'browser_automation',
            'total_results': len(results),
            'results': results
        }
        
        filepath = f"/Users/duljan/.openclaw/workspace/projects/openclaw-journey/{filename}"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Sparade till: {filename}")
        
        # Skriv rapport
        print("\\nğŸ“Š RANKING:")
        for i, item in enumerate(results[:10], 1):
            analysis = item['analysis']
            print(f"\\n#{i} | {item['title'][:60]}...")
            print(f"   ğŸ’° {item.get('price', 'N/A')} | â­ {analysis['score']}/100")
            print(f"   ğŸ“‹ {analysis['recommendation']}")

if __name__ == '__main__':
    # KÃ¶r med synlig webblÃ¤sare fÃ¶rsta gÃ¥ngen (sÃ¥ Adrian ser)
    print("ğŸ¬ Startar browser automation...")
    print("   Du kommer se en Chrome-fÃ¶nster Ã¶ppnas")
    print("   (StÃ¤ng det inte fÃ¶rrÃ¤n skrapningen Ã¤r klar!)\\n")
    
    scraper = BlocketBrowserScraperWithScoring(headless=False)
    results = scraper.scrape_all()
    
    if results:
        analyzed = scraper.analyze_results(results)
        scraper.save_and_report(analyzed)
        
        # Skicka notifiering om bra deals
        good_deals = [r for r in analyzed if r['analysis']['score'] >= 60]
        if good_deals:
            print(f"\\nğŸš¨ Hittade {len(good_deals)} bra deals!")
            print("   Skickar notifiering...")
            # HÃ¤r skulle vi skicka Telegram-notis
    else:
        print("\\nâš ï¸  Inga resultat. Kolla /tmp/blocket_debug.html")
    
    print("\\nâœ… KLAR!")
